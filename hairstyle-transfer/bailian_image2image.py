import json
import base64
import requests
import cv2
import numpy as np
from io import BytesIO
from PIL import Image
import os
import time


class BailianImage2ImageHairTransfer:
    def __init__(self, api_key=None, endpoint=None):
        self.api_key = api_key or os.getenv('BAILIAN_API_KEY')
        self.endpoint = endpoint or os.getenv('BAILIAN_ENDPOINT',
                                              'https://dashscope.aliyuncs.com/api/v1/services/aigc/image2image/image-synthesis')

        if not self.api_key:
            print("âš ï¸  è­¦å‘Š: æœªè®¾ç½®ç™¾ç‚¼APIå¯†é’¥")
            print("ğŸ’¡ è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export BAILIAN_API_KEY=your_api_key")
        else:
            print(f"âœ… åˆå§‹åŒ–ç™¾ç‚¼å‘å‹è¿ç§»æœåŠ¡ (ç†å‘å¸ˆä¸“ç”¨)")
            print(f"   API Key: {self.api_key[:10]}...")
            print(f"   Endpoint: {self.endpoint}")

    def image_to_base64(self, image_array):
        """å°†OpenCVå›¾åƒè½¬æ¢ä¸ºbase64 (ä¼˜åŒ–ä¸ºPNGæ ¼å¼)"""
        if image_array is None or image_array.size == 0:
            raise ValueError("æ— æ•ˆçš„å›¾åƒæ•°æ®")

        # ç¡®ä¿å›¾åƒå°ºå¯¸åˆè§„ (384x384 ~ 1024x1024)
        image_array = self._preprocess_image(image_array)

        # ä¿å­˜ä¸ºPNGé¿å…å‹ç¼©å¤±çœŸ
        _, buffer = cv2.imencode('.png', image_array)
        base64_data = base64.b64encode(buffer).decode('utf-8')
        return f"data:image/png;base64,{base64_data}"

    def call_image2image_api(self, prompt, src_image_base64, dst_image_base64):
        """è°ƒç”¨ç™¾ç‚¼API (ç†å‘å¸ˆä¸“ç”¨ä¼˜åŒ–)"""
        if not self.api_key:
            raise Exception("ç™¾ç‚¼APIå¯†é’¥æœªè®¾ç½®")

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "X-DashScope-Async": "enable"
        }

        # ç†å‘å¸ˆä¸“ç”¨è¯·æ±‚ä½“ (ç¬¦åˆå®˜æ–¹APIè§„èŒƒ)
        request_data = {
            "model": "wan2.5-i2i-preview",
            "input": {
                "prompt": prompt,
                "images": [
                    src_image_base64,  # å‘å‹è®¾è®¡å›¾ä½œä¸ºç¬¬ä¸€å¼ å‚è€ƒå›¾
                    dst_image_base64   # å®¢æˆ·ç…§ç‰‡ä½œä¸ºç¬¬äºŒå¼ å‚è€ƒå›¾
                ]
            },
            "parameters": {
                "n": 1,
                "watermark": False  # ä¸æ·»åŠ æ°´å°
            }
        }

        try:
            print("ğŸš€ ç™¾ç‚¼APIè°ƒç”¨ (ç†å‘å¸ˆä¸“ç”¨æ¨¡å¼)")
            print(f"ğŸ“ æç¤ºè¯: {prompt}")
            print(f"ğŸ–¼ï¸  è¾“å…¥å›¾åƒ: å‘å‹è®¾è®¡å›¾ + å®¢æˆ·ç…§ç‰‡")

            response = requests.post(
                self.endpoint,
                headers=headers,
                json=request_data,
                timeout=120
            )

            if response.status_code == 200:
                result_data = response.json()
                print("âœ… APIè°ƒç”¨æˆåŠŸ")

                # å¤„ç†å¼‚æ­¥ä»»åŠ¡
                if "output" in result_data and "task_id" in result_data["output"]:
                    task_id = result_data["output"]["task_id"]
                    return self._wait_for_async_task(task_id)
                else:
                    print(f"âŒ æ— æ•ˆå“åº”: {json.dumps(result_data, indent=2)}")
                    raise Exception("APIå“åº”æ ¼å¼é”™è¯¯")

            else:
                error_data = response.json()
                error_code = error_data.get('code', 'æœªçŸ¥é”™è¯¯')
                error_msg = error_data.get('message', 'æœªçŸ¥é”™è¯¯ä¿¡æ¯')
                print(f"âŒ APIé”™è¯¯ {response.status_code}: {error_code} - {error_msg}")
                print(f"ğŸ”§ è¯·æ±‚æ•°æ®: {json.dumps(request_data, indent=2)}")
                raise Exception(f"{error_code}: {error_msg}")

        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise

    def _wait_for_async_task(self, task_id, max_wait_time=180):
        """ç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ (ç†å‘å¸ˆä¸“ç”¨ä¼˜åŒ–)"""
        print(f"â³ ç­‰å¾…å‘å‹è¿ç§»å®Œæˆ (ä»»åŠ¡ID: {task_id})")
        print("ğŸ’¡ ä¸“ä¸šå‘å‹è¿ç§»é€šå¸¸éœ€è¦60-120ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…...")

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        query_url = f"https://dashscope.aliyuncs.com/api/v1/tasks/{task_id}"
        start_time = time.time()
        poll_count = 0

        while time.time() - start_time < max_wait_time:
            poll_count += 1
            try:
                print(f"ğŸ” ç¬¬{poll_count}æ¬¡æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€...")
                response = requests.get(query_url, headers=headers, timeout=30)

                if response.status_code == 200:
                    status_data = response.json()
                    task_status = status_data.get("output", {}).get("task_status", "UNKNOWN")

                    print(f"ğŸ“Š ä»»åŠ¡çŠ¶æ€: {task_status}")

                    if task_status == "SUCCEEDED":
                        print("âœ… ä»»åŠ¡å®Œæˆï¼å¼€å§‹ä¸‹è½½ç”Ÿæˆå›¾åƒ")
                        # è·å–ç»“æœå›¾åƒ
                        if "output" in status_data and "results" in status_data["output"]:
                            if len(status_data["output"]["results"]) > 0:
                                image_url = status_data["output"]["results"][0]["url"]
                                return self._download_image(image_url)
                            else:
                                raise Exception("ä»»åŠ¡æˆåŠŸä½†æ— ç»“æœå›¾åƒ")
                        else:
                            raise Exception("æ— æ³•æ‰¾åˆ°ä»»åŠ¡ç»“æœ")
                    elif task_status == "FAILED":
                        error_msg = status_data.get("output", {}).get("message", "ä»»åŠ¡å¤±è´¥")
                        raise Exception(f"å¼‚æ­¥ä»»åŠ¡å¤±è´¥: {error_msg}")
                    else:
                        print("â³ ä»»åŠ¡å¤„ç†ä¸­ï¼Œç­‰å¾…10ç§’åç»§ç»­æŸ¥è¯¢...")
                        time.sleep(10)
                else:
                    print(f"âŒ æŸ¥è¯¢å¤±è´¥: {response.status_code}")
                    time.sleep(10)

            except Exception as e:
                print(f"âŒ æŸ¥è¯¢é”™è¯¯: {e}")
                time.sleep(10)

        raise Exception(f"ä»»åŠ¡ç­‰å¾…è¶…æ—¶ (è¶…è¿‡ {max_wait_time} ç§’)")

    def _download_image(self, image_url):
        """ä¸‹è½½ç”Ÿæˆçš„å›¾åƒ (ç†å‘å¸ˆä¸“ç”¨ä¼˜åŒ–)"""
        print(f"ğŸ“¥ ä¸‹è½½ä¸“ä¸šå‘å‹è¿ç§»ç»“æœ: {image_url}")
        try:
            response = requests.get(image_url, timeout=30)
            if response.status_code == 200:
                image_array = np.frombuffer(response.content, np.uint8)
                result_image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)

                if result_image is not None:
                    print(f"âœ… å›¾åƒä¸‹è½½æˆåŠŸï¼Œå°ºå¯¸: {result_image.shape}")
                    return result_image
                else:
                    raise Exception("å›¾åƒè§£ç å¤±è´¥")
            else:
                raise Exception(f"ä¸‹è½½å¤±è´¥: {response.status_code}")

        except Exception as e:
            raise Exception(f"å›¾åƒä¸‹è½½å¤±è´¥: {str(e)}")

    def transfer_hair(self, src_image, dst_image, strength=0.8):
        """æ ¸å¿ƒåŠŸèƒ½ï¼šå‘å‹è¿ç§» (ç†å‘å¸ˆä¸“ç”¨ä¼˜åŒ–)"""
        print("ğŸ’‡â€â™‚ï¸ å¼€å§‹ä¸“ä¸šå‘å‹è¿ç§» (ç†å‘å¸ˆä¸“ç”¨æ¨¡å¼)")
        print(f"ğŸ’ª è¿ç§»å¼ºåº¦: {strength:.1f} (0.0-1.0)")

        try:
            # 1. é¢„å¤„ç†å›¾åƒ (ç¡®ä¿å°ºå¯¸åˆè§„)
            src_image = self._preprocess_image(src_image)
            dst_image = self._preprocess_image(dst_image)

            # 2. ç”Ÿæˆä¸“ä¸šæç¤ºè¯ (å…³é”®ä¼˜åŒ–ç‚¹)
            prompt = self._generate_hair_prompt()

            # 3. è½¬æ¢å›¾åƒä¸ºbase64
            src_base64 = self.image_to_base64(src_image)
            dst_base64 = self.image_to_base64(dst_image)

            # 4. è°ƒç”¨API
            result_image = self.call_image2image_api(prompt, src_base64, dst_base64)

            # 5. è°ƒæ•´å°ºå¯¸åŒ¹é…å®¢æˆ·ç…§ç‰‡
            target_height, target_width = dst_image.shape[:2]
            result_image = cv2.resize(result_image, (target_width, target_height))

            print("âœ… ä¸“ä¸šå‘å‹è¿ç§»å®Œæˆï¼")
            print("ğŸ’¡ è¾“å‡ºç»“æœï¼šå®¢æˆ·æ‹¥æœ‰æ‚¨è®¾è®¡çš„å‘å‹")
            return result_image

        except Exception as e:
            print(f"âŒ å‘å‹è¿ç§»å¤±è´¥: {e}")
            print("âš ï¸ ä½œä¸ºå¤‡ä»½ï¼Œè¿”å›åŸå§‹å®¢æˆ·ç…§ç‰‡")
            return dst_image

    def _generate_hair_prompt(self):
        """ç”Ÿæˆç†å‘å¸ˆä¸“ç”¨æç¤ºè¯ (å…³é”®ä¼˜åŒ–ç‚¹)"""
        return (
            "å°†ç¬¬ä¸€å¼ å›¾ç‰‡çš„å‘å‹è¿ç§»åˆ°ç¬¬äºŒå¼ å›¾ç‰‡çš„äººç‰©ä¸Šã€‚"
            "å…³é”®è¦æ±‚ï¼šå®Œå…¨ä¿æŒç¬¬äºŒå¼ å›¾ç‰‡äººç‰©çš„é¢éƒ¨ç‰¹å¾ã€è„¸å‹ã€è‚¤è‰²ä¸å˜ã€‚"
            "ä¸è¦æ”¹å˜æˆ–å˜å½¢é¢éƒ¨ã€‚"
            "åªæ›¿æ¢å‘å‹ï¼Œä¿ç•™äººç‰©å…¶ä»–æ‰€æœ‰ç‰¹å¾ã€‚"
            "æœ€ç»ˆç»“æœåº”è¯¥æ˜¯ï¼šç¬¬äºŒå¼ å›¾ç‰‡çš„åŒä¸€ä¸ªäººï¼Œä½†æ‹¥æœ‰ç¬¬ä¸€å¼ å›¾ç‰‡çš„å‘å‹ã€‚"
            "ç…§ç‰‡å†™å®é£æ ¼ï¼Œè‡ªç„¶å…‰ç…§ï¼Œå‘å‹èåˆæ— ç¼ï¼Œä¸“ä¸šå“è´¨ã€‚"
        )

    def _preprocess_image(self, image):
        """å›¾åƒé¢„å¤„ç† (ç†å‘å¸ˆä¸“ç”¨ä¼˜åŒ–)"""
        h, w = image.shape[:2]
        min_size = 384
        max_size = 1024

        # ç¡®ä¿å›¾åƒå°ºå¯¸åœ¨è¦æ±‚èŒƒå›´å†…
        if min(h, w) < min_size:
            scale = min_size / min(h, w)
            new_w = int(w * scale)
            new_h = int(h * scale)
            image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            print(f"ğŸ–¼ï¸  å›¾åƒå·²æ”¾å¤§è‡³: {new_w}x{new_h} (æ»¡è¶³APIæœ€å°å°ºå¯¸è¦æ±‚)")

        if max(h, w) > max_size:
            scale = max_size / max(h, w)
            new_w = int(w * scale)
            new_h = int(h * scale)
            image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            print(f"ğŸ–¼ï¸  å›¾åƒå·²ç¼©å°è‡³: {new_w}x{new_h} (æ»¡è¶³APIæœ€å¤§å°ºå¯¸è¦æ±‚)")

        return image

    def test_api_connection(self):
        """æµ‹è¯•APIè¿æ¥ (ç†å‘å¸ˆä¸“ç”¨)"""
        if not self.api_key:
            return False, "APIå¯†é’¥æœªè®¾ç½®"

        try:
            # åˆ›å»ºä¸“ä¸šæµ‹è¯•å›¾åƒ
            test_image1 = np.ones((512, 512, 3), dtype=np.uint8) * 255
            cv2.circle(test_image1, (256, 256), 100, (0, 0, 0), -1)  # å‘å‹

            test_image2 = np.ones((512, 512, 3), dtype=np.uint8) * 200
            cv2.rectangle(test_image2, (50, 50), (462, 462), (150, 150, 150), -1)  # å®¢æˆ·é¢éƒ¨

            # æµ‹è¯•è°ƒç”¨
            result = self.call_image2image_api(
                self._generate_hair_prompt(),
                self.image_to_base64(test_image1),
                self.image_to_base64(test_image2)
            )

            if result is not None:
                return True, "APIè¿æ¥æˆåŠŸ (ç†å‘å¸ˆä¸“ç”¨æ¨¡å¼)"
            else:
                return False, "APIè¿”å›ç©ºç»“æœ"

        except Exception as e:
            return False, f"APIè¿æ¥å¤±è´¥: {str(e)}"


# å·¥å‚å‡½æ•° (è‡ªåŠ¨æ£€æµ‹APIé…ç½®)
def create_image2image_transfer():
    api_key = os.getenv('BAILIAN_API_KEY')
    endpoint = os.getenv('BAILIAN_ENDPOINT',
                         'https://dashscope.aliyuncs.com/api/v1/services/aigc/image2image/image-synthesis')

    if api_key:
        print("ğŸ”‘ æ£€æµ‹åˆ°APIé…ç½®ï¼Œä½¿ç”¨ä¸“ä¸šå‘å‹è¿ç§»æœåŠ¡")
        return BailianImage2ImageHairTransfer(api_key, endpoint)
    else:
        print("ğŸ”§ æœªæ£€æµ‹åˆ°APIé…ç½®ï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å¼ (ä»…ç”¨äºéªŒè¯)")
        return _DemoHairTransfer()


class _DemoHairTransfer:
    """æ¼”ç¤ºæ¨¡å¼ (ä»…ç”¨äºéªŒè¯æµç¨‹ï¼Œä¸ç”ŸæˆçœŸå®æ•ˆæœ)"""

    def transfer_hair(self, src_image, dst_image, strength=0.8):
        print("ğŸ­ æ¼”ç¤ºæ¨¡å¼: æ¨¡æ‹Ÿå‘å‹è¿ç§»æ•ˆæœ (å®é™…ä½¿ç”¨éœ€è®¾ç½®APIå¯†é’¥)")
        result = dst_image.copy()

        # æ·»åŠ æ¼”ç¤ºæ°´å°
        cv2.putText(result, "DEMO MODE - SET API KEY FOR REAL RESULTS",
                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        cv2.putText(result, f"Strength: {strength:.1f}",
                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

        return result